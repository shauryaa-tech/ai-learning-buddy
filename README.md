![Preview of AI Learning Buddy](ai learning buddy/frontend/image.png)




## üåê Live Architecture

ai-learning-buddy/
‚îú‚îÄ‚îÄ backend/
‚îÇ   ‚îú‚îÄ‚îÄ app.py               # LangGraph backend using Gemini
|   ‚îî‚îÄ‚îÄ requirements.txt     # Python dependencies          
‚îú‚îÄ‚îÄ frontend/
‚îÇ   ‚îú‚îÄ‚îÄ index.html           # Web UI
‚îÇ   ‚îú‚îÄ‚îÄ style.css            # Styling
‚îÇ   ‚îî‚îÄ‚îÄ script.js            # Frontend logic


# üß† AI Learning Buddy

AI Learning Buddy is a web-based AI tutor built with *FastAPI (Python backend)* and *Vanilla JavaScript (frontend)*. It helps students improve by providing:

-> Personalized learning suggestions based on quiz scores
-> Follow-up topic explanations
-> Practice questions for weak areas


## ‚öô How to Run the Project

## üîß 1. Install Backend Dependencies

Make sure you have Python 3.10+. Then run:

```bash
pip install fastapi uvicorn langgraph langchain-core langchain-google-genai pydantic

# üîß 2. Set Google Gemini API Key

## You must set the environment variable:

- export GOOGLE_API_KEY=your_key_here

Or replace it directly in app.py for testing:--

- os.environ["GOOGLE_API_KEY"] = "your_key_here"


## üöÄ 3. Run the Backend Server

uvicorn app:app --reload --port 8000


üåç 4. Open the Frontend

-> Open frontend/index.html in your browser (just double-click or serve using Live Server in VS Code).



üß† What Happens Behind the Scenes

Backend (app.py)
	‚Ä¢	FastAPI handles API endpoints.
	‚Ä¢	Gemini model generates responses using langchain_google_genai.
	‚Ä¢	LangGraph defines a flow:
	‚Ä¢	get_input ‚Üí analyze ‚Üí END
	‚Ä¢	/recommend returns study suggestions.
	‚Ä¢	/answer returns detailed topic explanations.


Frontend (script.js)
	‚Ä¢	Takes user input
	‚Ä¢	Sends POST requests to /recommend and /answer
	‚Ä¢	Dynamically updates DOM to show output and answer buttons



## Coding Description 

‚úÖ Python (app.py)
	‚Ä¢	FastAPI and CORSMiddleware allow communication with frontend
	‚Ä¢	UserInput and TopicInput define input structure
	‚Ä¢	Gemini LLM is initialized using API key
	‚Ä¢	AI flow:
	‚Ä¢	Takes input
	‚Ä¢	Constructs prompt for Gemini
	‚Ä¢	Returns clean, bullet-pointed study advice

‚úÖ JavaScript (script.js)
	‚Ä¢	generate(): Sends input to /recommend and shows suggestions
	‚Ä¢	Creates a button for each topic: clicking it calls /answer
	‚Ä¢	formatText(): cleans Gemini response for HTML
	‚Ä¢	goBack(): resets the UI


## Setup
1. Clone repository
2. Install backend dependencies: `pip install -r backend/requirements.txt`
3. Run backend: `uvicorn backend.app:app --reload`
4. Open `frontend/index.html` in browser


üë®‚Äçüíª Author

Created by Shaurya Pratap Singh
Powered by FastAPI, LangGraph, and Gemini AI
